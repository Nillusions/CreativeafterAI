// Module: prompting
window.LOADED_MODULE = {
    "id": "prompting",
    "number": "03",
    "title": "Prompting: How to talk to AI so it gets stuff done!",
    "tagline": "AI gives back what you give it. Better input = better output.",
    "icon": "square-pen",
    "color": "#fda121",
    "tabs": {
        "introduction": "<div class='intro-header-cards'><div class='intro-card learn'><h4>What you will learn</h4><ul><li>What is prompting?</li><li>Different techniques for prompting.</li><li>How to think when prompting?</li></ul></div><div class='intro-card who'><h4>Who is this for</h4><ul><li>Anyone using an AI chatbot or agent or similar</li></ul></div></div><h3>The Art of Talking to AI</h3><p>We are living in a time where you can have access to the most powerful thinking tool ever built, right in your pocket, for free.\nBut here's the thing.\nMost people are using it wrong.\nNot because they're not smart. But because nobody taught them how to talk to it. <br>\nThink about it. We spend years learning how to write emails, how to give presentations, how to communicate with people. But AI? We just type something and hope for the best. <br>\nThat changes today.</p><p><strong>Prompting is not a technical skill. It's a communication skill. And just like how the way you ask a question determines the answer you get, the way you talk to AI determines everything it gives back to you.\nRemember our novice driver? You wouldn't just say \"take me home.\" You'd give directions, set expectations, and define boundaries.\nThat's exactly what this module is about.</strong></p>",
        "Thinking": "<h3>How to think when using AI</h3><p>AI isn't magic — it's a very sophisticated pattern-matcher that needs clear direction. The quality of your output is directly tied to the quality of your input.</p><p><strong>The Novice Driver</strong><br>\nImagine you're exhausted after a long day and you hand your car keys to a brand new driver and say:\n\n<em>\"Take me home, fast.</em>\"<br>\n\nThey're eager, they're willing, they want to do a good job. So they floor it. <br>\n<br>\nThey cut through a dirt road because it's shorter on the map. They jump a speed breaker at full speed. They squeeze through a construction zone to save 3 minutes. They get you home fast — technically they did exactly what you asked. <br>\n<br>\nBut your car is rattling, your back is destroyed, and you're more stressed than when you started. <br>\n<br>\n<em>Did they do anything wrong? \"Not really!\" You said fast. They went fast. </em><br>\n\nYou forgot to say — take the main road, follow traffic rules, keep it smooth, don't damage the car.</p><p><strong>That's AI.</strong> <br>\n\nPowerful, eager, and completely literal. It will execute your instruction perfectly — but it has no common sense about what you actually meant. The more clearly you define your destination, your route, your speed, and your boundaries, the better your ride will be</p><h3>World building in prompting</h3><p><em>The more vague your world, the more AI has to guess. And when AI guesses, it defaults to the most average, generic version of what you asked for.\nBut when you build a rich, specific world, AI has something to work with. It stops guessing and starts performing.</em></p><p>When you sit down with AI, you are not just asking a question. You are building a world for it to operate in.\nThink about it like a movie director. Before the camera rolls, the director doesn't just say \"action.\" They have already decided the setting, the characters, the mood, the lighting, the tone. Every detail is intentional. The more complete that world is, the better the performance you get from your actors.<br>\nAI works the same way. <br>\nWhen you give AI a prompt, you are essentially setting the stage. The more complete your world is, the more accurate and useful the response will be.</p><h3>Why this matters technically</h3><p>Large Language Models like ChatGPT or Claude do not \"think\" the way humans do. They predict. Every word they generate is based on the context you have given them. <br>\nHere is the key insight: AI has no memory of who you are, no idea what you need, and no understanding of your world unless you tell it. <br>\n<strong>Every conversation starts at zero.</strong><br>\nSo when you type a vague prompt, the AI fills in the missing context on its own, pulling from the most average, most common version of that request it has ever seen. You get a generic answer because you gave it a generic world. <>\nWhen you build a rich context, the AI has real material to work with. It narrows down from billions of possible responses to the ones that actually fit your world. <br>\n\n<strong>LLMs process your entire prompt as what is called a \"context window.\" Everything you write sits in that window and influences every single word the AI generates next. The richer and more specific that context window is, the more the probability of getting a useful response goes up.</strong></p><h3>The Four Walls of Your World</h3><ul><li><strong> Identity</strong> — Who are you and what is your situation? \"I am a first year medical student preparing for an exam\" gives completely different results than just asking a medical question cold. The AI now knows your level, your purpose, and your context.</li><li><strong>Role</strong> — Who is the AI in this world? \"Act as an experienced product manager with a background in SaaS startups\" is fundamentally different from just asking a generic question. You are giving the AI a character to inhabit, which shapes its vocabulary, its assumptions, and its perspective.</li><li><strong>Task and Goal</strong> — What exactly do you need and why? Not just \"write me an email\" but \"write me a follow up email to a client who went silent after our proposal, the goal is to re-engage without sounding desperate.\" The why is just as important as the what.</li><li><strong>Constraints and Format</strong> — What are the rules of this world? Length, tone, format, what to avoid, who the audience is. These are the guardrails that stop the AI from going off in a direction you did not intend.</li></ul><p><em>A Real Comparison <br>\nWeak world: \"Write me a marketing post.\" <br>\nStrong world: \"I run a small home bakery in Bangalore targeting working mothers aged 28 to 40. Write me an Instagram caption for a new whole wheat birthday cake. The tone should be warm and personal, not corporate. Keep it under 60 words and end with a call to action.\" <br>\nSame tool. Completely different result. The only difference is the world you built around your request.</em></p><p><strong>Every time you sit down with AI, ask yourself: have I given it enough world to work with? Have I told it who I am, who it is, what I need, and what the rules are?\nThe people getting remarkable results from AI are not using better tools. They are building better worlds.</strong></p>",
        "Techniques": "<table><thead><tr><th>Type</th><th>Explanation</th></tr></thead><tbody><tr><td><strong>Zero shot prompt</strong></td><td>Directly asking LLM something without much details/ context.</td></tr><tr><td><strong>Few shot prompting</strong></td><td>Giving LLM some context [not detailed] and then asking it questions.</td></tr><tr><td><strong>Descriptive prompts</strong></td><td>Giving AI detailed context and data in one shot and asking it for answers or tasks in one go.</td></tr><tr><td><strong>Prompt chaining</strong></td><td>Giving the LLM sequential context to get answers/ the last output becomes the next input - Chain of thought.</td></tr><tr><td><strong>Markdown/ XML/ JSON prompt</strong></td><td>Formatting prompts in markdown/ XML/ json structure will generate better answers while keeping the context window and token usage less. Markdown has an upperhand as it consumes less tokes and is the most simplified version.</td></tr><tr><td><strong>Role - Task -Format - Example -  Input</strong></td><td>ell AI who to be, what to do, how to present it, show it an example, and then give it your raw material.</td></tr></tbody></table><h3>Tokens and Context Window</h3><p>Every time you talk to AI, it does not read your words the way you do. It breaks everything down into small chunks called tokens. A token is roughly a word or part of a word. When you type a prompt, it becomes a series of tokens. Now, every AI model has a limit to how many tokens it can hold in its memory at one time. This is called the context window. Think of it like a whiteboard. You can only write so much before you run out of space. Everything inside that whiteboard is what the AI can \"see\" and use to generate its response. Once you go beyond that limit, the AI starts forgetting what was said earlier in the conversation. This is why long conversations can sometimes feel like the AI loses track of what you were originally asking for.</p>",
        "Iteration & Mistakes": "<h3>Iteration Strategies & Common Mistakes in Prompting</h3><p>Getting a great response from AI almost never happens in one shot. Think of your first prompt as a rough draft, not a final order. The real skill is knowing how to refine and push the AI closer to what you actually want.</p><ul><li><strong>Strategy 1: React to What You Got</strong> — Simply respond to the output. \"Make it shorter.\" \"Make it more casual.\" \"That missed the point, here is what I actually need.\" You do not need to start over. The AI remembers your entire conversation and builds on it.</li><li><strong>Strategy 2: Go Step by Step</strong> — Instead of asking for everything at once, break it down. Ask for an outline first. Review it. Then ask it to write section by section. This gives you control at every stage.</li><li><strong>Strategy 3: Ask AI to Challenge Itself</strong> — After it gives you a response, ask it \"what are the weaknesses in this?\" or \"how would you improve this?\" This forces the model to think critically about its own output and often gives you a much better version.</li></ul><p><em><strong>The Mindset Shift</strong>\nStop treating AI like a vending machine where one input gives you the perfect output. Start treating it like a collaboration, where you and the AI work toward something together, one iteration at a time.</em></p><h3>Common Mistakes in Prompting</h3><p>Most people do not get bad results from AI because the tool is bad. They get bad results because of habits that are easy to fix once you are aware of them.</p><ul><li><strong>Mistake 1: Being Too Vague</strong> — \"Write me something about leadership\" tells the AI almost nothing. No audience, no purpose, no tone, no length. The AI has to guess everything and it defaults to the most generic version possible.</li><li><strong>Mistake 2: Asking Multiple Things at Once</strong> — Write me a blog post, summarise it, make a LinkedIn post out of it and give me 5 hashtags\" in one prompt often produces mediocre versions of all four. Break it into steps and you get better results at each stage.</li><li><strong>Mistake 3: No Context About Yourself</strong> — The AI does not know who you are unless you tell it. A student, a CEO, and a freelancer asking the same question should get very different answers. Tell it who you are.</li><li><strong>Mistake 4: Giving Up After One Try</strong> — Most people try once, do not like the result, and either accept it or abandon the tool. The first response is a starting point, not the final answer. Iterate.</li><li><strong>Mistake 5: Trusting Everything Blindly</strong> — AI sounds confident even when it is wrong. Always verify facts, statistics, and any critical information before using it.</li></ul>",
        "Ethics & Limitations": "<h3>Ethics and Limitations</h3><p>AI is powerful but it is not perfect, and understanding its limitations makes you a smarter, more responsible user.</p><ul><li><strong>Hallucinations</strong> — AI sometimes makes things up and presents them with complete confidence. Fake statistics, wrong dates, non existent research papers. It is not lying intentionally. It is predicting what sounds right based on patterns. Always verify anything critical before acting on it.</li><li><strong>Bias</strong> — AI is trained on human generated data, which means it carries human biases. It can reflect cultural, gender, and racial biases depending on how questions are framed. Be aware of this especially when using AI for hiring, research, or decision making.</li><li><strong>It Has a Knowledge Cutoff</strong> — Most AI models are trained on data up to a certain point in time. They do not know about recent events unless they have access to live search. Do not rely on AI for breaking news or the latest developments in fast moving fields.</li><li><strong>It Does Not Actually Understand You</strong> — AI does not have feelings, intentions, or genuine understanding. It is pattern matching at a massive scale. It can sound empathetic, creative, and intelligent but it is always predicting the next most likely word, not truly comprehending your situation.</li><li><strong>Privacy</strong> — Be careful about what you share with AI tools. Do not paste sensitive company data, personal information, or confidential documents into public AI tools unless you are certain about the platform's privacy policy.</li></ul>",
        "Hands On Practice": "<h3>Hands On Practice</h3><p>This is where it all comes together. Here are three exercises you can try right now.</p><p><em>Exercise 1: The Makeover\nTake a weak prompt you have used before or use this one: \"Give me tips on time management.\" Now rebuild it using the Role, Task, Format, Example, Input framework. Run both versions and compare the results.</em></p><p><em>Exercise 2: The Iteration Challenge\nStart with a simple prompt: \"Write me a short introduction about myself for LinkedIn.\" Then spend 5 minutes only using follow up instructions to improve it. No restarting. Only refining. See how far you can take it through iteration alone.</em></p><p><em>Exercise 3: Build Your World\nPick something you genuinely need help with right now, a work task, a personal project, anything. Before you type a single word into AI, write down the four walls of your world. Who are you, who is the AI, what is the task and goal, what are the constraints. Then build your prompt from that and see what you get.</em></p>"
    }
};
