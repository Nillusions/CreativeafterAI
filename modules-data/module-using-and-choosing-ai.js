// Module: using-and-choosing-ai
window.LOADED_MODULE = {
    "id": "using-and-choosing-ai",
    "number": "01",
    "title": "How to think about AI and choosing AI tools",
    "tagline": "A practical guide for anyone trying to make sense of it all",
    "icon": "roller-coaster",
    "color": "#e894ff",
    "tabs": {
        "introduction": "<div class='intro-header-cards'><div class='intro-card learn'><h4>What you will learn</h4><ul><li>A clear mental model of what AI actually does </li><li>A decision framework for deciding when to use AI and when not to</li><li>Practical habits that make your AI use smarter over time</li></ul></div><div class='intro-card who'><h4>Who is this for</h4><ul><li>For those who work, create, problem-solve, or build things and want to use AI tools without being overwhelmed or misled. </li><li>Not for AI researcher or Engineers</li></ul></div></div><p>Letâ€™s cut through the noise for a second.\n<br>\nLet's be real for a moment. AI is everywhere right now. It's in your inbox, your search engine, your work tools, and probably your phone. Everyone has an opinion about it some people think it's going to change everything, others think it's overhyped, and most of us are just trying to figure out where it actually fits in our lives and work.\n<br>\nBefore you can make good decisions about using AI, you need a working model of what it actually does. The biggest mistake people make with AI is treating it like a smarter version of Google. It isn't. Google is an index; AI is an engine.</p><h3>Understanding What AI Actually Is (And Isn't)</h3><p>Modern AI â€” the kind you interact with in tools like chatbots, image generators, writing assistants, and code helpers â€” is mostly built on what are called large language models (LLMs) or similar pattern-recognition systems. Here's the simplest way to think about what they do:</p><p><strong>âœ¦ KEY IDEA\n- AI models are very sophisticated pattern-matching machines. They've been trained on enormous amounts of human-generated content and learned to predict what a useful, coherent response looks like given a particular input.</strong></p><p>That's it. It's not thinking the way you think. It's not reasoning from first principles the way a mathematician does. It's producing outputs that are statistically likely to be correct, coherent, and relevant  based on patterns in its training data.\n<br>\nThis is why AI can write a pretty good essay about almost anything but can also confidently get a basic fact completely wrong. It's optimizing for coherence, not truth.</p><h3>What changed recently [from 2025]</h3><p>AI doesn't have values, stakes, or context the way you do. It doesn't know what actually matters in your situation</p><ul><li><strong>Reasoning models arrived</strong> â€” Tools like OpenAI's o1/o3 and DeepSeek R1 don't just pattern-match, they actually work through problems step by step. This is a genuine capability jump.</li><li><strong>Agentic AI went mainstream</strong> â€” AI tools can now take actions on your behalf browsing the web, writing and running code, sending emails. 2025 was the year agents moved from demos to real deployments. [As of publishing this module it might have already become advanced]</li><li><strong>Multimodal is now standard</strong> â€” The leading models all handle text, images, audio, and documents in the same conversation. It's no longer a differentiator,it's a baseline.</li><li><strong>The market got crowded</strong> â€” ChatGPT, Claude, Gemini, Grok, DeepSeek, Cursor, Perplexity.... the tool landscape expanded fast. Knowing how to choose matters more than ever.</li></ul>",
        "understanding AI": "<h3>Understanding What AI Actually Is (And Isn't)</h3><p>Before you can make good decisions about using AI, you need a working model of what it actually does. Not a technical one â€” just enough to stop it from surprising you.</p><h3>How It Works (The Short Version)</h3><p>Most AI tools you interact with today â€” chatbots, writing assistants, coding helpers, image generators â€” are built on large language models (LLMs) or similar systems. Here's the most honest way to describe them:\n\n</p><p><em>âœ¦ KEY IDEA - AI models are trained on enormous amounts of human-generated content and have learned to produce responses that are statistically likely to be useful, coherent, and relevant. The newer reasoning models go a step further â€” they can work through problems step by step before answering. But none of them understand the world the way you do. They don't have goals, stakes, or judgment.\n</em></p><p>This is why a good AI can write a polished essay on almost any topic â€” but also confidently get a basic fact completely wrong. It's optimizing for coherence and plausibility, not truth. The newer reasoning models are better at accuracy in structured tasks like math and code, but they still make mistakes, especially in areas requiring real-world context or common sense.</p><h3>Strengths and Weaknesses</h3><table><thead><tr><th>AI is genuinely strong at...</th><th>AI still struggles with...</th></tr></thead><tbody><tr><td><strong>Writing, drafting, summarizing, reformatting</strong></td><td>Factual accuracy â€” it fabricates confidently</td></tr><tr><td><strong>Generating code and explaining it</strong></td><td>Real-time information (knowledge cutoffs still exist)</td></tr><tr><td><strong>Brainstorming and generating options</strong></td><td>Knowing what it doesn't know</td></tr><tr><td><strong>Synthesizing multiple sources quickly</strong></td><td>Nuanced judgment and weighing competing values</td></tr><tr><td><strong>Step-by-step reasoning (reasoning models)</strong></td><td>Tasks needing deep domain expertise or lived context</td></tr><tr><td><strong>Tasks needing deep domain expertise or lived context</strong></td><td>Truly novel creative or strategic thinking</td></tr></tbody></table><p><em>âš   IMPORTANT\nNever rely on AI for medical, legal, financial, or safety-critical decisions without verification from a qualified professional. Reasoning models are better than before â€” but 'better' is not the same as 'reliable'.</em></p><h3>Cutting Through the Hype</h3><p>Every week there's a headline that either crowns AI as the future of everything or dismisses it as overblown. Here's a calibration table:</p><table><thead><tr><th>You'll hear...</th><th>The more accurate reality</th></tr></thead><tbody><tr><td><strong>\"AI will replace all jobs\"</strong></td><td>AI replaces tasks within jobs more than entire roles â€” at least for now. But it is reshaping white-collar work faster than most expected.</td></tr><tr><td><strong>\"AI is always right â€” it's very smart\"</strong></td><td>Fluency is not intelligence. AI sounds authoritative even when it's wrong. Reasoning models reduced this problem but didn't eliminate it.</td></tr><tr><td><strong>\"AI is just a gimmick\"</strong></td><td>\"AI is just a gimmick\"\tFor the right tasks, AI is genuinely transformative. 42% of code written in 2025 was AI-assisted. The question is which tasks.</td></tr><tr><td><strong>\"You need to be technical to use AI\"</strong></td><td>The best AI tools today are conversational. Technical skills help with advanced use cases but aren't required to get real value.</td></tr><tr><td><strong>\"AI agents will do everything autonomously\"</strong></td><td>Agentic AI is real and improving fast. But it works best on structured, verifiable tasks. Complex judgment calls still need humans.</td></tr></tbody></table>",
        "how to think about AI": "<h3>How to Think Before You Reach for an AI Tool</h3><p>One of the most common mistakes people make with AI is treating it like a reflex â€” the moment a task appears, they open a chatbot. The better habit is to pause and ask three quick questions before you start.</p><h3>Three Questions to Ask First</h3><table><thead><tr><th>Question</th><th>Why it matters</th></tr></thead><tbody><tr><td><strong>What am I actually trying to achieve?</strong></td><td>AI is a means, not an end. Vague goals produce vague outputs. Be specific about what 'done' looks like before you start.</td></tr><tr><td><strong>Is this the kind of task AI is good at?</strong></td><td>Pattern-based work, synthesis, drafts = strong AI territory. Judgment calls, sensitive decisions, real-time facts = use AI cautiously or not at all.</td></tr><tr><td><strong>What does getting this wrong cost me?</strong></td><td>What does getting this wrong cost me?\tLow stakes? Use AI freely. High stakes? Treat AI as a starting point and verify the output yourself before acting on it.</td></tr></tbody></table><h3>The AI Decision Map</h3><p><strong>âœ“  Use AI freely when:</strong>\n    The task is repetitive, pattern-based, or benefits from speed at volume\n    You need a first draft or starting point to react to\n    You can review and verify the output before it goes anywhere important\n<strong>âš   Use AI with caution when:</strong>\n    Factual accuracy is critical and you'll struggle to verify it\n    The task involves sensitive personal, legal, or financial decisions\n<strong>âœ—  Don't rely on AI when:</strong>\n    You need current, real-time information (use search instead, or an AI with web access)\n    Deep professional expertise or lived human judgment is the core of the task</p><h3>Replacement vs. Augmentation</h3><p>This is the most useful mental shift you can make. There are two ways to frame AI in your work:\n<strong>Replacement thinking: \"Can AI do this instead of me?\"</strong>\n<strong>Augmentation thinking: \"How can AI make me sharper, faster, or more thorough at this?\"</strong><br>\nThe second framing almost always gets better results. The people who get the most from AI aren't the ones handing everything over â€” they're the ones who figure out where AI handles the mechanical parts so they can focus on the judgment parts.\n</p><p><em>ðŸ’¡ TIP\nInstead of: \"Can AI write this email for me?\" â€” try:\n  â€¢  \"Can AI give me 3 different ways to phrase this so I can pick the best one?\"\n  â€¢  \"Can AI draft the structure so I just need to fill in the parts only I know?\"\n  â€¢  \"Can AI handle the formatting while I focus on the message?\"</em></p><p><em>While AI exhibits agentic capabilities and AI automation can offer greater reliability, what's discussed here is the foundational thinking you need before any of that becomes useful to you.</em></p>",
        "tools landscape": "<h3>The AI Tool Landscape in 2026</h3><p>The AI tool space is crowded and moving fast. Walking into it without a map is overwhelming. The good news is most tools fall into a handful of clear categories â€” and knowing the categories makes evaluating specific products much easier.</p><h3>The Major Categories</h3><table><thead><tr><th>Categories</th><th>What They Do</th><th>Current Leaders</th><th>What's New</th></tr></thead><tbody><tr><td><strong>General Assistants</strong></td><td>Conversational AI you interact with in natural language â€” writing, analysis, brainstorming, coding, Q&A, summarizing.</td><td>ChatGPT (OpenAI), Claude (Anthropic), Gemini (Google), Grok (xAI), DeepSeek</td><td>All the major models are now multimodal (text, image, documents). Reasoning modes (like o3 or Claude's extended thinking) are available for harder problems. â€¢\tThese are still the best starting point for most everyday AI use cases.</td></tr><tr><td><strong>Coding & Development Tools</strong></td><td>AI embedded in code editors that can write, explain, debug, and now refactor entire codebases.</td><td>Claude code, Cursor (growing fast), GitHub Copilot, Replit AI â€” and general assistants like Claude are strong at coding too</td><td>Agent Mode in tools like Cursor can now traverse an entire project, create multiple files, and refactor architecture autonomously. As of 2025, 42% of code written was AI-assisted.</td></tr><tr><td><strong>Search & Research Tools</strong></td><td>AI that searches the web and synthesizes results into cited answers â€” replacing traditional search for many knowledge workers.</td><td>Perplexity (with real-time web access), NotebookLM (for your own documents), Elicit (for research papers)</td><td>Perplexity's Pro Search and Comet browser launched in 2025. These tools close one of the biggest gaps in general AI â€” real-time information.</td></tr><tr><td><strong>Creative Generation Tools</strong></td><td>Generate, edit, and remix creative assets from text or audio prompts â€” images, video, voice, music, and full creator workflows. This is one of the fastest-moving and most practically accessible areas of AI for non-technical users.</td><td>Midjourney and Adobe Firefly for images, Runway Gen-3, Sora, and Kling for video, ElevenLabs for voice and text-to-speech, Suno and Udio for music generation, Descript and Opus Clip for podcast and video editing, HeyGen for AI avatars and video dubbing, Canva AI for design and social content.</td><td>Video generation went from novelty to production-usable â€” Runway and Kling are now in real content workflows. ElevenLabs became the standard for realistic AI voice, used in audiobooks, podcasts, and dubbed video. HeyGen's lip-synced video translation went mainstream. Suno and Udio can generate a full song with vocals and instrumentation from a single text prompt. Adobe Firefly embedded generative fill and expand directly into Photoshop and Illustrator, making AI part of the professional design workflow rather than a separate tool. Canva AI brought that same accessibility to anyone making social content or presentations.</td></tr></tbody></table><h3>Quick Reference: The Landscape at a Glance</h3><table><thead><tr><th>Tools</th><th>Best For</th><th>Watch Out</th></tr></thead><tbody><tr><td><strong>General Assistants (ChatGPT, Claude, Gemini)</strong></td><td>Writing, analysis, brainstorming, coding</td><td>Confident but wrong answers â€” always verify facts</td></tr><tr><td><strong>Coding Tools (Claude code, Cursor, Copilot)</strong></td><td>Code generation, debugging, refactoring</td><td>Security flaws in generated code; review it carefully</td></tr><tr><td><strong>Search & Research (Perplexity, NotebookLM)</strong></td><td>Real-time info, document synthesis</td><td>Still prone to errors; use as a starting point</td></tr><tr><td><strong>Productivity AI (Notion AI, MS Copilot)</strong></td><td>Speeding up everyday work tasks</td><td>Quality varies; often behind the frontier models</td></tr><tr><td><strong>Specialized / Vertical (Harvey, Suki, Jasper)</strong></td><td>Domain-specific tasks with compliance needs</td><td>Claims need validating with domain experts</td></tr><tr><td><strong>Creative Generation (Midjourney, Runway, ElevenLabs, Descript, Canva AI)</strong></td><td>Images, video, voice, music, and creator workflows</td><td>Copyright unsettled commercially; voice/avatar tools require ethical care around consent</td></tr></tbody></table><p><em>One important new category: Agentic AI tools (like Claude Code, OpenAI Operator) can now take actions â€” browsing, coding, filing â€” not just respond to questions. They're most reliable when the task is structured and the output is easy to verify. Treat them with extra scrutiny for anything consequential.</em></p>",
        "choosing right tool": "<h3>How to Choose the Right AI Tool</h3><p>You know your goal, you've got a rough map of what's out there â€” now how do you actually pick? Here's a practical framework, plus the red flags to watch for.</p><h3>Criteria That Actually Matter</h3><p><strong>Task Fit</strong>\nDoes this tool actually do what you need, for your specific use case? Test it on your own real tasks, not demos. A general assistant might outperform a specialized tool for your particular workflow, or vice versa.\n</p><p><strong>Data Privacy & Security</strong>\nThis matters more than most people realize, especially in a professional context. Before entering any sensitive data, ask: Does this tool store my inputs and use them for model training? Is there an enterprise or privacy mode? Does it comply with my organization's data policies?\n</p><p><strong>Integration With Your Workflow</strong>\nThe best tool in the world won't help if it creates friction. Does it live inside a product you already use (like Notion, VS Code, or Google Workspace)? The lower the switching cost, the more consistently you'll actually use it.\n</p><p><em>Be cautious of any tool that: makes strong accuracy claims without specifics, acts on AI output without showing it to you first, has vague or missing data privacy policies, or claims to be the best AI for everything â€” which usually means it's not the best at anything specific.</em></p><h3>A Quick Selection Scorecard</h3><table><thead><tr><th>Criterion</th><th>What to Ask</th><th>Score [1-5]</th></tr></thead><tbody><tr><td><strong>Task Fit</strong></td><td>Does it do what I need for my actual use cases?</td><td>______</td></tr><tr><td><strong>Output Quality</strong></td><td>Is the quality good enough for my specific domain?</td><td>______</td></tr><tr><td><strong>Privacy & Security</strong></td><td>Is my data safe? Does it meet my organization's policies?</td><td>______</td></tr><tr><td><strong>Workflow Integration</strong></td><td>Does it fit into how I already work, or create friction?</td><td>______</td></tr><tr><td><strong>Cost vs. Value</strong></td><td>Is what I'm paying worth the time/quality gain?</td><td>______</td></tr></tbody></table><p><em>A tool scoring 4+ across all criteria is a strong choice. A tool scoring under 3 on Privacy or Task Fit is likely the wrong tool regardless of how good it is elsewhere.</em></p>",
        "using AI": "<h3>Using AI Well â€” Habits That Make a Difference</h3><p>Choosing the right tool is half the battle. The other half is how you use it. The difference between mediocre and excellent results usually isn't the tool â€” it's the habits you bring to it.</p><table><thead><tr><th>Weak Prompt</th><th>A Stronger Prompt</th></tr></thead><tbody><tr><td><strong>\"Write me an email\"</strong></td><td>\"Write a 150-word email to a client explaining a 2-week project delay. Be apologetic but solution-focused.\"</td></tr><tr><td><strong>\"Explain machine learning\"</strong></td><td>\"Explain machine learning in plain English for someone who works with spreadsheets but has no coding background.\"</td></tr><tr><td><strong>\"Help me with this document\"</strong></td><td>\"Help me with this document\"\t\"Summarize this document in 4 bullet points focused specifically on the financial implications for Q3.\"</td></tr></tbody></table><p><em>Good prompts usually include:\n  â€¢  What you want (the output format and content)\n  â€¢  Who it's for (so it can match the right tone and complexity)\n  â€¢  Any constraints (word count, tone, what to avoid)\n  â€¢  Context it might not know (internal info, nuances of your situation)\n</em></p><h3>Good prompts usually include:   â€¢  What you want (the output format and content)   â€¢  Who it's for (so it can match the right tone and complexity)   â€¢  Any constraints (word count, tone, what to avoid)   â€¢  Context it might not know (internal info, nuances of your situation)</h3><p>â€¢\tAlways review before you use. Treat AI output like a first draft from a capable but fallible assistant. Good enough to react to â€” not good enough to ship without your eyes on it.\nâ€¢\tVerify facts independently. If AI gives you a statistic, quote, or specific claim you're going to rely on or share publicly, check it from an original source. Every time.\nâ€¢\tIterate rather than accept. Don't take the first response and move on. Push back. Say what you liked and what missed the mark. AI tools respond well to conversational refinement.\nâ€¢\tKeep judgment with humans. Use AI for the informational and mechanical parts of decisions. The weighing of values, context, and consequences â€” that stays with you.\nâ€¢\tSave prompts that work. When you find a prompt that consistently produces great output for a recurring task, save it. Over time this becomes one of your most useful assets.\n</p><h3>Traps to Avoid</h3><p><em>The Confidence Trap: Trusting AI because it sounds authoritative. Fluency is not correctness. The more polished an AI response sounds, the more important it is to verify it.</em></p><p><em>The Automation Trap: Using AI to automate tasks you don't fully understand yourself. If something goes wrong, you won't catch it.</em></p><p><em>The Shortcut Trap: Using AI to skip developing understanding you actually need. Efficiency is fine; hollowing out your own expertise is a long-term problem.</em></p><p><em>The Novelty Trap: Reaching for AI because it's there and feels modern, not because it's the right tool. Sometimes a Google search, a spreadsheet, or your own brain is faster and better.</em></p><p>AI is not magic, and it's not the enemy. It's a tool â€” a genuinely powerful one that's getting more capable at a pace most of us are still adjusting to. Reasoning models, agentic systems, multimodal capabilities â€” these aren't future promises anymore, they're things you can use today.\n\nBut the people who will get the most out of all of this aren't the most technical or the most enthusiastic about AI. They're the ones who think clearly about what they're trying to achieve, match their tools to their tasks, stay appropriately skeptical, and keep their own judgment in the loop.</p><p><em><strong>The goal isn't to use AI as much as possible. It's to use it in the right places, in the right way â€” to get better outcomes than you'd get without it.</strong></em></p>"
    }
};
